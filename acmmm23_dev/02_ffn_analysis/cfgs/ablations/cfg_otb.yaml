BASE_VARS:
  benchmark: "OTB100"

ABLATIONS:
  train_seeds:
    - 7
    - 123
    - 1111
  batch_sizes:
#    - 128
    - 256
    - 512
#    - 1024
  overlap_thresholds:
    - [0.1]
    - [0.2]
    - [0.3]
    - [0.4]
    - [0.5]
    - [0.6]
    - [0.7]
    - [0.8]
    - [0.9]
  num_epochs:
    - 5
#    - 100
#    - 200
#    - 500
  base_lrs:
#    - 0.5
    - 0.25
    - 0.1
  min_lrs:
#    - 0.05
    - 0.01
    - 0.001
  loss_types:
    - "CE"
    - "WCE"
  model_types:
#    - "NN_statistics"
    - "NN_dense_encoding"

MODELS:
  NN_statistics:
    dimensions:
     - [ 768, 100, 32, 2 ]
     - [ 768, 256, 64, 2 ]
    layers:
     - [ "fc", "fc", "fc" ]
     - [ "fc", "fc", "fc" ]
    hidden_activations:
     - [ "LeakyReLU", "LeakyReLU" ]
     - [ "LeakyReLU", "LeakyReLU" ]
    batchnorm_layers:
     - [ true, true ]
     - [ true, true ]
    dropout_probs:
     - [ 0.2, 0.2 ]
     - [ 0.2, 0.2 ]

  NN_dense_encoding:
    dimensions:
      - [ 262144, 2048, 256, 32, 2 ]
      - [ 262144, 2048, 64, 2 ]
    layers:
      - [ "fc", "fc", "fc", "fc" ]
      - [ "fc", "fc", "fc"]
    hidden_activations:
      - [ "LeakyReLU", "LeakyReLU", "LeakyReLU" ]
      - [ "LeakyReLU", "LeakyReLU" ]
    batchnorm_layers:
      - [ true, true, true ]
      - [ true, true ]
    dropout_probs:
      - [ 0.2, 0.2, 0.2 ]
      - [ 0.2, 0.2 ]
